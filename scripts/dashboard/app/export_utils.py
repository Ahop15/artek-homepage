"""
 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â•šâ•â•â•â•â–ˆâ–ˆâ•‘
â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘
â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â•â•

Export Utilities for ARTEK AI Worker Dashboard

Copyright (C) 2025 RÄ±za Emre ARAS <r.emrearas@proton.me>
"""

import io
import json
import zipfile
from typing import List, Dict, Any, Callable, Optional
from datetime import datetime


def _to_blockquote(text: str) -> str:
    """Convert text to markdown blockquote format (prefix each line with >)."""
    lines = text.split('\n')
    return '\n'.join(f"> {line}" for line in lines)


def export_session_markdown(
        session: Dict[str, Any],
        blocks: List[Dict[str, Any]],
        locale: str = 'tr'
) -> str:
    """
    Export a conversation session to beautifully formatted markdown.

    Args:
        session: Session metadata (chain_id, started_at, etc.)
        blocks: List of conversation blocks
        locale: Language for labels ('tr' or 'en')

    Returns:
        Formatted markdown string
    """
    # Locale-specific labels
    labels = {
        'tr': {
            'title': 'ARTEK AI KonuÅŸma KaydÄ±',
            'session_id': 'Oturum ID',
            'date': 'Tarih',
            'total_messages': 'Toplam Mesaj',
            'token_usage': 'Token KullanÄ±mÄ±',
            'input': 'giriÅŸ',
            'output': 'Ã§Ä±kÄ±ÅŸ',
            'blocks': 'blok',
            'question': 'Soru',
            'answer': 'Cevap',
            'knowledge_search': 'Bilgi Arama',
            'query': 'Sorgu',
            'search_results': 'Arama SonuÃ§larÄ±',
            'source': 'Kaynak',
            'metadata': 'Metadata',
            'tokens': 'Token',
            'latency': 'Gecikme',
            'model': 'Model',
            'footer': 'Bu dosya ARTEK AI Worker Dashboard tarafÄ±ndan oluÅŸturulmuÅŸtur.',
            'generated_at': 'OluÅŸturulma Tarihi'
        },
        'en': {
            'title': 'ARTEK AI Conversation Log',
            'session_id': 'Session ID',
            'date': 'Date',
            'total_messages': 'Total Messages',
            'token_usage': 'Token Usage',
            'input': 'input',
            'output': 'output',
            'blocks': 'blocks',
            'question': 'Question',
            'answer': 'Answer',
            'knowledge_search': 'Knowledge Search',
            'query': 'Query',
            'search_results': 'Search Results',
            'source': 'Source',
            'metadata': 'Metadata',
            'tokens': 'Tokens',
            'latency': 'Latency',
            'model': 'Model',
            'footer': 'This file was generated by ARTEK AI Worker Dashboard.',
            'generated_at': 'Generated At'
        }
    }

    l = labels.get(locale, labels['en'])

    # Build markdown
    md = [f"# {l['title']}", "", f"**{l['session_id']}:** `{session['chain_id'][:16]}...`  ",
          f"**{l['date']}:** {session['started_at']} - {session['ended_at']}  ",
          f"**{l['total_messages']}:** {session['block_count']} {l['blocks']}  ",
          f"**{l['token_usage']}:** {session['total_input_tokens']:,} {l['input']} / {session['total_output_tokens']:,} {l['output']}  ",
          "", "---", ""]

    # Header

    # Each conversation block
    for i, block in enumerate(blocks, 1):
        # Question header
        md.append(f"## {l['question']} {i}")
        md.append("")
        md.append(block['user_message'])
        md.append("")

        # Tool calls (if any)
        if block.get('tool_calls') and len(block['tool_calls']) > 0:
            for tool_call in block['tool_calls']:
                md.append(f"### ğŸ” {l['knowledge_search']}")
                md.append("")

                # Extract query
                query = tool_call.get('input', {})
                if isinstance(query, dict):
                    query_text = query.get('query', str(query))
                else:
                    query_text = str(query)

                md.append(f"**{l['query']}:** `{query_text}`")
                md.append("")

                # Search results in collapsible section
                output = tool_call.get('output', '')
                if output:
                    md.append("<details>")
                    md.append(f"<summary>{l['search_results']}</summary>")
                    md.append("")
                    md.append("```")
                    # Truncate very long outputs
                    if len(output) > 2000:
                        md.append(output[:2000] + "\n... (truncated)")
                    else:
                        md.append(output)
                    md.append("```")
                    md.append("")
                    md.append("</details>")
                    md.append("")

        # Answer (wrapped in blockquote to isolate inner markdown)
        md.append(f"### {l['answer']}")
        md.append("")
        md.append(_to_blockquote(block['assistant_response']))
        md.append("")

        # Metadata (optional, in collapsible)
        md.append("<details>")
        md.append(f"<summary>ğŸ“Š {l['metadata']}</summary>")
        md.append("")
        md.append(f"- **{l['tokens']}:** {block['tokens_in']:,} {l['input']} / {block['tokens_out']:,} {l['output']}")
        md.append(f"- **{l['latency']}:** {block['latency_ms']}ms")
        md.append(f"- **{l['model']}:** {block['model']}")
        md.append("")
        md.append("</details>")
        md.append("")

        # Separator between Q&A pairs
        md.append("---")
        md.append("")

    # Footer
    md.append(f"_{l['footer']}_  ")
    md.append(f"_{l['generated_at']}: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}_")

    return "\n".join(md)


def export_session_json(
        session: Dict[str, Any],
        blocks: List[Dict[str, Any]],
        include_hashes: bool = False
) -> str:
    """
    Export a conversation session to JSON format.

    Args:
        session: Session metadata
        blocks: List of conversation blocks
        include_hashes: Whether to include blockchain hashes

    Returns:
        JSON string
    """
    export_data = {
        "metadata": {
            "chain_id": session['chain_id'],
            "started_at": session['started_at'],
            "ended_at": session['ended_at'],
            "block_count": session['block_count'],
            "total_input_tokens": session['total_input_tokens'],
            "total_output_tokens": session['total_output_tokens'],
            "exported_at": datetime.now().isoformat()
        },
        "conversations": []
    }

    for block in blocks:
        conversation = {
            "index": block['block_index'],
            "timestamp": block['created_at'],
            "user_message": block['user_message'],
            "assistant_response": block['assistant_response'],
            "tokens": {
                "input": block['tokens_in'],
                "output": block['tokens_out']
            },
            "latency_ms": block['latency_ms'],
            "model": block['model']
        }

        # Add tool calls if present
        if block.get('tool_calls') and len(block['tool_calls']) > 0:
            conversation["tool_calls"] = block['tool_calls']

        # Add blockchain hashes if requested
        if include_hashes:
            conversation["blockchain"] = {
                "block_hash": block['block_hash'],
                "prev_hash": block['prev_hash'],
                "context_hash": block['context_hash']
            }

        export_data["conversations"].append(conversation)

    return json.dumps(export_data, ensure_ascii=False, indent=2)


def get_export_filename(session: Dict[str, Any], extension: str) -> str:
    """
    Generate a filename for the export.

    Args:
        session: Session metadata
        extension: File extension ('md' or 'json')

    Returns:
        Filename string
    """
    chain_short = session['chain_id'][:8]
    date_str = session['started_at'].split(' ')[0]
    return f"artek-ai-conversation-{date_str}-{chain_short}.{extension}"


def format_file_size(size_bytes: float) -> str:
    """
    Format bytes to human-readable size string.

    Args:
        size_bytes: Size in bytes

    Returns:
        Formatted string (e.g., "1.5 MB")
    """
    if size_bytes < 1024:
        return f"{size_bytes:.0f} B"
    elif size_bytes < 1024 * 1024:
        return f"{size_bytes / 1024:.1f} KB"
    else:
        return f"{size_bytes / (1024 * 1024):.1f} MB"


def create_bulk_export_zip(
        sessions: List[Dict[str, Any]],
        get_blocks_func: Callable[[str], List[Dict[str, Any]]],
        locale: str = 'tr',
        progress_callback: Optional[Callable[[int, int, str], None]] = None
) -> bytes:
    """
    Create a ZIP file containing all sessions as markdown files.

    Structure:
        artek-ai-export-YYYY-MM-DD/
        â”œâ”€â”€ ip-hash-abc123/
        â”‚   â”œâ”€â”€ session-2025-12-24-def456.md
        â”‚   â””â”€â”€ session-2025-12-23-ghi789.md
        â””â”€â”€ ip-hash-xyz789/
            â””â”€â”€ session-2025-12-24-jkl012.md

    Args:
        sessions: List of sessions with ip_hash, chain_id, etc.
        get_blocks_func: Function to get blocks for a chain_id
        locale: Language for markdown export ('tr' or 'en')
        progress_callback: Optional callback(current, total, message)

    Returns:
        ZIP file as bytes
    """
    # Create in-memory ZIP
    zip_buffer = io.BytesIO()

    # Generate export folder name
    export_date = datetime.now().strftime('%Y-%m-%d')
    export_folder = f"artek-ai-export-{export_date}"

    total_sessions = len(sessions)

    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
        for idx, session in enumerate(sessions):
            # Progress callback
            if progress_callback:
                progress_callback(
                    idx + 1,
                    total_sessions,
                    f"{session['chain_id'][:8]}..."
                )

            # Get blocks for this session
            blocks = get_blocks_func(session['chain_id'])

            if not blocks:
                continue

            # Generate markdown content
            md_content = export_session_markdown(session, blocks, locale=locale)

            # Create folder structure: ip-hash-xxx/session-date-chainid.md
            ip_hash_short = (session.get('ip_hash') or 'unknown')[:12]
            ip_folder = f"ip-{ip_hash_short}"

            # Session filename
            date_str = session['started_at'].split(' ')[0]
            chain_short = session['chain_id'][:8]
            filename = f"session-{date_str}-{chain_short}.md"

            # Full path in ZIP
            file_path = f"{export_folder}/{ip_folder}/{filename}"

            # Write to ZIP
            zf.writestr(file_path, md_content.encode('utf-8'))

    # Return bytes
    zip_buffer.seek(0)
    return zip_buffer.read()


def get_bulk_export_filename() -> str:
    """
    Generate filename for bulk export ZIP.

    Returns:
        Filename string (e.g., "artek-ai-export-2025-12-24.zip")
    """
    date_str = datetime.now().strftime('%Y-%m-%d')
    return f"artek-ai-export-{date_str}.zip"
